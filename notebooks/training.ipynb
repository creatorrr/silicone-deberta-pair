{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd9cf1-a9e1-4fc1-81c6-c29ab3b8b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets pandas transformers torch tables imbalanced-learn >/dev/null\n",
    "!pip install --user simpletransformers >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799862c5-6cd8-4452-a36c-df2415b282df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset silicone_merged_dataset (/home/jupyter/.cache/huggingface/datasets/diwank___silicone_merged_dataset/balanced/1.0.0/39a3b335ff82e7218cebbe6700a2bf12b187741b2768b59fc53a80ca49c89722)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b185a4f0e8748aab3d3a35087210938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "silicone_merged = load_dataset(\"diwank/silicone-merged\", \"balanced\")\n",
    "\n",
    "train_df = silicone_merged[\"train\"].to_pandas()\n",
    "eval_df = silicone_merged[\"validation\"].to_pandas()\n",
    "test_df = silicone_merged[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69616b-9554-4671-96d5-7c9b3e9bfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "project = \"da-silicone-combined\"\n",
    "\n",
    "# Turn off debug logs\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "# Turn off tokenizers parallelism\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# model configuration\n",
    "from simpletransformers.classification import (\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "\n",
    "model_args = ClassificationArgs(\n",
    "    n_gpu=2,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=3e-5,\n",
    "    # train_batch_size=160,\n",
    "    scheduler=\"polynomial_decay_schedule_with_warmup\",\n",
    "    polynomial_decay_schedule_power=2,\n",
    "    evaluate_during_training=True,\n",
    "    evaluate_during_training_verbose=True,\n",
    "    evaluate_during_training_steps=2000,\n",
    "\n",
    "    wandb_project=project,\n",
    "    use_multiprocessing=False,\n",
    "    use_multiprocessing_for_evaluation=False,\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\"roberta\", \"distilroberta-base\", args=model_args, num_labels=11)\n",
    "\n",
    "# Train model\n",
    "model.train_model(train_df, eval_df=eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a5edb-2a03-4180-adbf-9006f2980ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Evaluate the model\n",
    "combined = pd.concat([eval_df, test_df])\n",
    "result, model_outputs, wrong_predictions = model.eval_model(combined)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:latest"
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
